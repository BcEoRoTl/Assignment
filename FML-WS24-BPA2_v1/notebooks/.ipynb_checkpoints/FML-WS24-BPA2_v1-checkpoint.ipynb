{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff0c2cfb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# FML - Winter Semester 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e588f37-9ddb-4453-9112-4c15fd236c10",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83efe17f56b35f41f9cb801e02c99e2a",
     "grade": false,
     "grade_id": "cell-1e7085ade66f208c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "panel-layout": {
     "height": 167.3671875,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "# Bonus Points Assignment 2\n",
    "\n",
    "<div style=\"text-align: right;font-size: 0.8em\">Document Version 1.0.0</div>\n",
    "For detailed task instructions, please refer to the assignment PDF.\n",
    "\n",
    "This assignment requires `numpy`, `matplotlib`, `tqdm`, and `torch` to run. If one of these imports fails, please install the corresponding library and make sure that you have activated the corresponding virtual environment. If the problem persists, please seek help on the forums or use [the JupyterHub profile of the lecture](https://jupyter.rwth-aachen.de/hub/spawn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80b2d1d3-51cc-49d6-9ddb-8e300a13e195",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8b979bb2ca250a5f879468b7fb05fe8",
     "grade": false,
     "grade_id": "cell-22df8e7374f80cd6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "ROOT = Path().resolve()\n",
    "\n",
    "# This contains the path to the data / folder of the assignment\n",
    "# DO NOT change the path to the data. Only use data and dump files at this location.\n",
    "DATA = ROOT / 'data'\n",
    "EXAMPLE_IMAGE = DATA / 'example_image.png'\n",
    "\n",
    "CHECKS_PASSED_MESSAGE = 'Great! All checks were passed.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31ecd26-55de-4b23-81cb-410e027e2609",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "635a7c9472681716825877f48250a047",
     "grade": false,
     "grade_id": "cell-3c9df225719d6c46",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the next cell to check that all files are at the correct location. Do not change the location of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ce02cd-28d9-4447-a530-ed9b316556ab",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "520381019ba07d7ae48ccb26ce44fda4",
     "grade": false,
     "grade_id": "cell-ead1cdcb48d7be49",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert EXAMPLE_IMAGE.exists(), f\"Training data is missing.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfd3355-98d2-4bf6-bf60-a296b3df3d4a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "75e398681d5cbd53c857fef1e9a4ea3c",
     "grade": false,
     "grade_id": "cell-a37cad18a3b59941",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "panel-layout": {
     "height": 119.1875,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "## Linear Layers\n",
    "All individual operations, including activation functions, will be represented as layers in this model.\n",
    "The abstract `Layer` interface defines three methods. Make yourself familiar with the `Layer` class and its methods. You don't have to implement anything here. Simply run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9845fc-ed17-44ea-9abe-6560a5799305",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49184a94dcce3a760a556e07671b74b1",
     "grade": false,
     "grade_id": "cell-ffbfe1d7a9b9b7fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class Layer(ABC):\n",
    "    def __init__(self):\n",
    "        \"\"\" Initializes the layer.\n",
    "        \n",
    "        Please DON'T change the names of the variables that are already defined in this method.\n",
    "        \"\"\"\n",
    "        self.input = None  # during every forward pass, we will later store the inputs to that forward pass\n",
    "        self.output = None  # during every forward pass, we will later store the outputs of that forward pass\n",
    "        self.gradient = None  # during every backward pass, we will later store the input gradient from the next layer\n",
    "    \n",
    "    @abstractmethod\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Performs a forward pass of the layer.\n",
    "\n",
    "        Args:\n",
    "            x: Input for this layer as a numpy array.\n",
    "\n",
    "        Returns:\n",
    "            The output of this layer as a numpy array.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def backward(self, gradient: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Performs a backward pass of the layer that determines the gradient.\n",
    "\n",
    "        Args:\n",
    "            gradient: Incoming gradient from the next layer as a numpy array.\n",
    "\n",
    "        Returns:\n",
    "            The gradient which will be passed to the previous layer as a numpy array.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def update(self, learn_rate: float) -> None:\n",
    "        \"\"\" Performs weight update.\n",
    "\n",
    "        Args:\n",
    "            learn_rate: Learning rate to use for the update.\n",
    "        \n",
    "        Returns:\n",
    "            Nothing. Instead, this function should update the internal state of the layer.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c7b2c0-e311-4cf1-9fea-a88399d604a4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "deae15c4e78940fd9e018bcd2b152588",
     "grade": false,
     "grade_id": "cell-aff077734fe884d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "panel-layout": {
     "height": 69.28125,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "__Question 1.1__ Implement the `MyLinearLayer` class. Leave the constructor (`__init__`) unchanged. Only modify the methods `forward`, `backward`, and `update`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11e2d8f6-b9b7-4534-8832-f9dfd276075d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0451449405c8baf423d837fadc6835f",
     "grade": false,
     "grade_id": "cell-1c93e877944446e3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMyLinearLayer\u001b[39;00m(\u001b[43mLayer\u001b[49m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_dim: \u001b[38;5;28mint\u001b[39m, output_dim: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Layer' is not defined"
     ]
    }
   ],
   "source": [
    "class MyLinearLayer(Layer):\n",
    "    def __init__(self, input_dim: int, output_dim: int):\n",
    "        pass\n",
    "        \"\"\" Initializes the linear layer with random weights.\n",
    "        \n",
    "        The weight matrix is initialized randomly.\n",
    "        The bias is initialized as 0.\n",
    "        \n",
    "        Please DON'T change the names of the variables that are already defined in this method.\n",
    "        You DON'T have to implement anything in this method.\n",
    "        \n",
    "        Args:\n",
    "            input_dim: Number of dimensions of the input. Inputs for the layer will have shape (batch_size, input_dim).\n",
    "            output_dim. Number of dimensions of the output. Outputs of the layer will have shape (batch_size, output_dim).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.w = (2 / input_dim) * np.random.randn(input_dim, output_dim)  # initialize weights with the He initializer\n",
    "        self.b = np.zeros(output_dim)  # initialize bias with zeros\n",
    "        \n",
    "        self.input = None  # during every forward pass, we will later store the inputs to that forward pass\n",
    "        self.output = None  # during every forward pass, we will later store the outputs of that forward pass\n",
    "        self.gradient = None  # during every backward pass, we will later store the input gradient from the next layer\n",
    "        \n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Performs a forward pass of the layer.\n",
    "\n",
    "        Use self.w as the weights and self.b as the bias for the forward pass.\n",
    "        The input to this function should be stored in the internal state (in the self.input variable).\n",
    "        The output of this function should be stored in the internal state (in the self.output variable).\n",
    "\n",
    "        Args:\n",
    "            x: Input batch matrix as a numpy array of shape (batch_size, input_dim).\n",
    "\n",
    "        Returns:\n",
    "            x: Output batch matrix as a numpy array of shape (batch_size, output_dim).\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def backward(self, gradient: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Performs a backward pass of the layer.\n",
    "        \n",
    "        The input gradient to this function should be stored in the internal state (in the self.gradient variable).\n",
    "\n",
    "        Args:\n",
    "            gradient: Incoming gradient from the next layer as a numpy array of shape (batch_size, output_dim).\n",
    "\n",
    "        Returns:\n",
    "            The gradient which will be passed to the previous layer as a numpy array of shape (batch_size, input_dim).\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def update(self, learn_rate: float) -> None:\n",
    "        \"\"\" Performs a weight update based on previously stored input and gradients.\n",
    "        \n",
    "        Args:\n",
    "            learn_rate: Learning rate to use for the update.\n",
    "        \n",
    "        Returns:\n",
    "            Nothing. Instead, this function should update the internal state of the layer.\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52eb95c-3491-4399-a789-f6d26f02eff4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc15c49338d2fd75e73f2bdf89068e97",
     "grade": false,
     "grade_id": "cell-7e7542937bbb9672",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "panel-layout": {
     "height": 148.84375,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "Run the following cell to make sure ...\n",
    "- ... the output of your forward pass has the correct shape.\n",
    "- ... the gradient produced by your backward pass has the correct shape.\n",
    "- ... the parameters (weights and bias) keep their shape after being updated.\n",
    "- ... the parameters (weights and bias) are changed by your update function.\n",
    "- ... the backward pass produces the correct results for some hand-picked input values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9252dde-ef04-4558-b362-6a757bd7cc8b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "738bbf69bf2615ccb2a2f83645c7b8ef",
     "grade": true,
     "grade_id": "test__linear-layer-sanity-check",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "panel-layout": {
     "height": 51.140625,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [],
   "source": [
    "__my_input = np.array([[1., 2., 3., 4., 5.], [1., 1., 2., 3., 5.]])\n",
    "__my_batch_size, __my_input_dim = __my_input.shape\n",
    "__my_output_dim = 16\n",
    "\n",
    "__my_linear_layer = MyLinearLayer(__my_input_dim, __my_output_dim)\n",
    "__initial_w, __initial_b = __my_linear_layer.w.copy(), __my_linear_layer.b.copy()\n",
    "\n",
    "# check if outputs of forward pass have the correct shape\n",
    "__my_output = __my_linear_layer.forward(__my_input)\n",
    "__target_output_shape = (__my_batch_size, __my_output_dim)\n",
    "assert __my_output.shape == __target_output_shape, f\"The output shape of a forward pass should have been {__target_output_shape}, but was {__my_output.shape}.\"\n",
    "assert __my_linear_layer.input is not None, \"You forgot to store the input to the forward pass.\"\n",
    "assert __my_linear_layer.output is not None, \"You forgot to store the output of the forward pass.\"\n",
    "\n",
    "\n",
    "# check if gradient computed by backward pass has the correct shape\n",
    "__my_gradient = __my_linear_layer.backward(__my_output)\n",
    "__target_gradient_shape = __my_batch_size, __my_input_dim\n",
    "assert __my_gradient.shape == __target_gradient_shape, f\"The output shape of a backward pass should have been {__target_gradient_shape}, but was {__my_gradient.shape}.\"\n",
    "assert __my_linear_layer.gradient is not None, \"Your forgot to store the input gradient to the output pass.\"\n",
    "assert np.allclose(__my_linear_layer.gradient, __my_output), \"You did not store the input gradient correctly. Did you store the output gradient instead?\"\n",
    "\n",
    "# check if updating the parameters keeps their shape and changes their values\n",
    "__my_linear_layer.update(1)\n",
    "assert __my_linear_layer.w.shape == __initial_w.shape, f\"Updating the weights of the layer should not change their shape, but shape changed from {__initial_w.shape} to {__my_linear_layer.w.shape}.\"\n",
    "assert __my_linear_layer.b.shape == __initial_b.shape, f\"Updating the bias of the layer should not change its shape, but shape changed from {__initial_b.shape} to {__my_linear_layer.b.shape}.\"\n",
    "assert np.any(__my_linear_layer.w != __initial_w), \"Updating the layer should change the weights (provided the gradient is not 0).\"\n",
    "assert np.any(__my_linear_layer.b != __initial_b), \"Updating the layer should change the bias (provided the gradient is not 0).\"\n",
    "\n",
    "# check if your backward pass produces the correct results for some arbitrary inputs\n",
    "__input = np.array([[0.10951508, 0.60428524, 0.79855139, 0.88042912]])\n",
    "__gradient = np.array([[0.45294082, 0.45302968, 0.37704032, 0.59154961]])\n",
    "\n",
    "__my_linear_layer = MyLinearLayer(4, 4)\n",
    "__my_linear_layer.w = np.array([\n",
    "    [1.28895006, -0.53177473, 0.09185581, -0.15011355],\n",
    "    [-0.42658447, 0.56021905, 0.06015589, 0.60129398],\n",
    "    [-0.20495445, 0.21709921, 0.29868546, -0.80570083],\n",
    "    [-0.20287495, 0.19254318, -1.00982607, -0.45614844]\n",
    "])\n",
    "__my_linear_layer.b = np.array([0., 0., 0., 0.])\n",
    "\n",
    "__output = __my_linear_layer.backward(__gradient.copy())\n",
    "__reference_output = np.array([[0.28874209, 0.43895475, -0.3584754, -0.65524215]])\n",
    "\n",
    "assert __output.shape == __reference_output.shape, f\"For a {__input.shape} input and an input dimensionality of {__input_dim} the output of your backward pass should be of shape {__reference_output.shape}, but was of shape {__output.shape}.\"\n",
    "assert np.allclose(__output - __reference_output, 0), f\"Your backward pass produces a wrong result for input {__input} and gradient {__gradient}.\"\n",
    "\n",
    "clear_output()\n",
    "CHECKS_PASSED_MESSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f98f42e-eb13-45e2-b38d-c264b7ef02d7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b24d9742bce685aef55148a0259fc30",
     "grade": true,
     "grade_id": "test__linear-layer-1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is used for grading. Do not remove. Do not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf314d55-b0e5-4efb-8685-866e41210716",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48767c13f94c05a9e26d720773e9ac24",
     "grade": true,
     "grade_id": "test__linear-layer-2",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is used for grading. Do not remove. Do not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a639d67-d0b3-436f-bee4-b637b0893e7c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "24c697f96663b1b38071d89f04d207bc",
     "grade": true,
     "grade_id": "test__linear-layer-3",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is used for grading. Do not remove. Do not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4053f621-0277-4c45-9933-4d6e442ccbbe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "039dde65675b941e47f81fb90b0acc55",
     "grade": true,
     "grade_id": "test__linear-layer-4",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is used for grading. Do not remove. Do not change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a297501-90be-40af-a160-d8dd3c2cd080",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5825a697d8bb448f3a478e59a4ff34cc",
     "grade": false,
     "grade_id": "cell-8d8c05df0aa2379c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "panel-layout": {
     "height": 51.640625,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "__Question 1.2__ Implement the `MyReLULayer` class. Only modify the methods `forward` and `backward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1095a542-baca-44fb-8a12-7cdc2e8d9a17",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d652f62ee150aa900b8f9cbe3fdbce7",
     "grade": false,
     "grade_id": "cell-3489203892d53748",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class MyReLULayer(Layer):\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Performs a forward pass of the ReLU layer.\n",
    "\n",
    "        The input to this function should be stored in the internal state (in the self.input variable).\n",
    "        The output of this function should be stored in the internal state (in the self.output variable).\n",
    "\n",
    "        Args:\n",
    "            x: Input batch matrix as a numpy array of shape (batch_size, input_dim).\n",
    "\n",
    "        Returns:\n",
    "            x: Output batch matrix as a numpy array of shape (batch_size, input_dim).\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def backward(self, gradient: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Performs a backward pass of the layer that determines the gradient.\n",
    "        \n",
    "        The input gradient to this function should be stored in the internal state (in the self.gradient variable).\n",
    "\n",
    "        Args:\n",
    "            gradient: Incoming gradient from the next layer as a numpy array of shape (batch_size, input_dim).\n",
    "\n",
    "        Returns:\n",
    "            The gradient which will be passed to the previous layer as a numpy array of shape (batch_size, input_dim).\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf0c10c-7039-41b9-9ace-23d4b05368d5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ddc4dc835be5b9c9f3859fed05fe1306",
     "grade": false,
     "grade_id": "cell-b1c29cece2401948",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "panel-layout": {
     "height": 131.703125,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "Run the following cell to make sure ...\n",
    "- ... the forward and backward pass produces an output of the correct shape.\n",
    "- ... the input is stored.\n",
    "- ... the output is stored.\n",
    "- ... the gradient is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e5f72f-420e-4136-a95e-2f7ae32fa1d8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b02ba0ba77c31647064ed29f64cbef4f",
     "grade": true,
     "grade_id": "test__relu-sanity-check",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "panel-layout": {
     "height": 51.140625,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [],
   "source": [
    "__my_input = np.array([[0, 1, 0, -1, 0], [0, 1, -1, 0.5, -0.5]])\n",
    "__my_batch_size, __my_input_dim = __my_input.shape\n",
    "\n",
    "__my_relu_layer = MyReLULayer()\n",
    "\n",
    "# check if outputs of forward pass have the correct shape\n",
    "__my_output = __my_relu_layer.forward(__my_input)\n",
    "assert __my_output.shape == __my_input.shape, f\"The output of a forward pass should not change the data shape, but changed from {__my_input.shape} to {__my_output.shape}.\"\n",
    "assert __my_relu_layer.input is not None, \"You forgot to store the input to the forward pass.\"\n",
    "assert __my_relu_layer.output is not None, \"You forgot to store the output of the forward pass.\"\n",
    "\n",
    "\n",
    "# check that the outputs are pointwise non-negative\n",
    "assert np.all(__my_output >= 0), f\"The output of a ReLU layer can't have negative values.\"\n",
    "\n",
    "\n",
    "# check if gradient computed by backward pass has the correct shape\n",
    "__my_gradient = __my_relu_layer.backward(__my_output)\n",
    "assert __my_gradient.shape == __my_output.shape, f\"The output of a backward pass should not change the gradient shape, but changed from {__my_output.shape} to {__my_gradient.shape}.\"\n",
    "assert __my_relu_layer.gradient is not None, \"Your forgot to store the gradient input to the output pass.\"\n",
    "assert np.allclose(__my_relu_layer.gradient, __my_output), \"You did not store the input gradient correctly. Did you store the output gradient instead?\"\n",
    "\n",
    "clear_output()\n",
    "CHECKS_PASSED_MESSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bde00b-29a7-4c5f-98e8-3500bc5a9397",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86c7a97aae0e54b1c77df31312420340",
     "grade": true,
     "grade_id": "test__relu-1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is used for grading. Do not remove. Do not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0fe432-740a-44c5-8c25-71a683d2d2a0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1410da185a20d0106040d746e0d9b8e",
     "grade": true,
     "grade_id": "test__relu-2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is used for grading. Do not remove. Do not change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3ac720-da5f-4a90-badf-b27734b6ad86",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "19f37971b5e7c11049a9dee510dbd4c8",
     "grade": false,
     "grade_id": "cell-57fe562bc052c1a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "panel-layout": {
     "height": 69.28125,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "__Question 1.3__ Implement the `MyNeuralNet` class. Only modify the methods `forward` and `backward`. You are not allowed to modify the constructor (`__init__`) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc6eec2-3f0f-4e82-9bee-fcc224d12d62",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95407e5f3c1c204866bfc7e7e0097bf4",
     "grade": false,
     "grade_id": "cell-12a136131b87d53a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class MyNeuralNet:\n",
    "    def __init__(self, n_hidden: int):\n",
    "        self.l1 = MyLinearLayer(input_dim=1, output_dim=n_hidden)\n",
    "        self.l2 = MyLinearLayer(input_dim=n_hidden, output_dim=1)\n",
    "        self.relu = MyReLULayer()\n",
    "    \n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Performs a forward pass through the complete network by successively calling the forward method of its layers.\n",
    "        \n",
    "        Args:\n",
    "            x: Batched input data as a numpy array of shape (batch_size, dim_input).\n",
    "            \n",
    "        Returns:\n",
    "            The output of the network as a numpy array of shape (batch_size, 1).\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def backward(self, y: np.ndarray) -> None:\n",
    "        \"\"\" Performs backward propagation by successively calling the backward method of its layers.\n",
    "        \n",
    "        Args:\n",
    "            y: The batch of target values corresponding to the last forwarded input as a numpy array of shape (batch_size, 1).\n",
    "            \n",
    "        Returns:\n",
    "            Nothing. The purpose of this method is to backpropagate the gradient through all layers of the model so that\n",
    "            they can obtain their respective gradients and later use that to update their parameters.\n",
    "        \"\"\"        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def update(self, learn_rate: float) -> None:\n",
    "        \"\"\" Updates the parameters of the model by successively calling the update method of its trainable layers.\n",
    "        \n",
    "        Args:\n",
    "            learn_rate: The learning rate with which to update the parameters.\n",
    "            \n",
    "        Returns:\n",
    "            Nothing. The purpose of this method is to update the internal parameters of the model.\n",
    "        \"\"\"        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b2ba7c-07e1-4b31-860c-423d7425bba2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f4ab1e0b040e1084d84d3a4372ef877f",
     "grade": true,
     "grade_id": "test__neural-net-sanity-check",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "panel-layout": {
     "height": 51.140625,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [],
   "source": [
    "__my_neural_net = MyNeuralNet(10)\n",
    "__batch = np.random.randn(100, 1)\n",
    "__predictions = __my_neural_net.forward(__batch)\n",
    "\n",
    "__target_shape = __batch.shape\n",
    "assert __predictions.shape == __target_shape, f\"For an input batch of shape {__batch.shape}, your model should output predictions of shape {__target_shape}, but produced predictions of shape {__predictions.shape}.\"\n",
    "\n",
    "assert hasattr(__my_neural_net, \"l1\"), \"You are not allowed to change the initialisation of the model.\"\n",
    "assert hasattr(__my_neural_net, \"relu\"), \"You are not allowed to change the initialisation of the model.\"\n",
    "assert hasattr(__my_neural_net, \"l2\"), \"You are not allowed to change the initialisation of the model.\"\n",
    "assert isinstance(__my_neural_net.l1, MyLinearLayer), \"You are not allowed to change the initialisation of the model.\"\n",
    "assert isinstance(__my_neural_net.relu, MyReLULayer), \"You are not allowed to change the initialisation of the model.\"\n",
    "assert isinstance(__my_neural_net.l2, MyLinearLayer), \"You are not allowed to change the initialisation of the model.\"\n",
    "\n",
    "clear_output()\n",
    "CHECKS_PASSED_MESSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d346cc8e-5e9f-4fd4-ba05-6e072137a92d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5dd7bba49bbf0e5148ce0ca6ee2d2577",
     "grade": true,
     "grade_id": "test__neural-net-1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is used for grading. Do not remove. Do not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ed9a5f-24dd-444d-8597-86731bd84edd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc092ce0fca7c55c2bd45ccadba20939",
     "grade": true,
     "grade_id": "test__neural-net-2",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is used for grading. Do not remove. Do not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f9f38b-d5f3-41da-84ec-a2ec1a2af744",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d514e8d9abef8a39b75eed2276cd0d3f",
     "grade": false,
     "grade_id": "cell-ce877644071c984f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Generator\n",
    "\n",
    "def get_training_data_myneuralnet(batch_size: int, N: int) -> Generator[np.ndarray, None, None]:\n",
    "    \"\"\" Generates data to train MyNeuralNet.\n",
    "    \n",
    "    This function outputs a generator, i.e., something that can be used in a `for` loop after the keyword `in`.\n",
    "    The generator iterates over batches of data, and each batch is a tuple containing the input and the output.\n",
    "    \n",
    "    Args:\n",
    "        batch_size: the batch size. Batches of inputs or outputs have shape (batch_size, 1). The only possible exception is the last batch; see below.\n",
    "        N: the total number of data points. If N % batch_size != 0, then the input and output of the last batch both have shape (N % batch_size, 1).\n",
    "    \n",
    "    Returns:\n",
    "        A generator of training data. Elements returned by the generator have the form (X, y), where X and y both have shape (b, 1), where b is the current batch's size.\n",
    "        \n",
    "    Remarks:\n",
    "        Calling this function multiple times with identical arguments will output the same data.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(1234)\n",
    "    last_batch_size = N % batch_size\n",
    "    incomplete_last_batch = last_batch_size != 0\n",
    "    n_batches = N // batch_size\n",
    "\n",
    "    def generate_data(n):\n",
    "        X = rng.uniform(-1, 1, n).reshape(-1, 1)\n",
    "        y = 2 + X * (X - 1) * (X + 1) + rng.normal(0, 0.01, size=(n,1))\n",
    "        return X, y\n",
    "\n",
    "    for _ in range(n_batches): \n",
    "        yield generate_data(batch_size)\n",
    "    if incomplete_last_batch:\n",
    "        yield generate_data(last_batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46a81a7-614a-4fb7-b2df-1cf94286a2a3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9677063ec3244dba96c7d502291daf0",
     "grade": false,
     "grade_id": "cell-fe965282e8b8ee87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__Question 1.4__ Implement the function `train_myneuralnet`. You only have to fill in the remaining part in the inner `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbb6588-f75f-4951-95eb-7d23870b23c5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29aacf1a383948c98f20a8ef0b2a79e6",
     "grade": false,
     "grade_id": "cell-74df1a78c6c7f0f9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def train_myneuralnet(model: MyNeuralNet, epochs: int, batch_size: int, learn_rate: float, N: int) -> list[float]:\n",
    "    \"\"\" Trains the model with the specified parameters.\n",
    "    \n",
    "    Args:\n",
    "        model: the instance of MyNeuralNet to train\n",
    "        epochs: the number of epochs, i.e., of complete passes over the data set\n",
    "        batch_size: the batch size to use in minibatch gradient descent\n",
    "        learn_rate: the learning rate to use in minibatch gradient descent\n",
    "        N: the number of data points in the training set. The training data is generated by the function get_training_data_myneuralnet.\n",
    "    \n",
    "    Returns:\n",
    "        losses: the list of losses at the end of each epoch\n",
    "    \"\"\"\n",
    "    # We store the losses for plotting later\n",
    "    losses = []\n",
    "    with tqdm(range(epochs)) as pbar:\n",
    "        for epoch in pbar:\n",
    "            # This variable cumulates the loss until the current batch\n",
    "            running_loss = 0.\n",
    "            for X_batch, y_batch in get_training_data_myneuralnet(batch_size, N):\n",
    "                # YOUR CODE HERE\n",
    "                raise NotImplementedError()\n",
    "            # At the end of the epoch, we divide running_loss by the number of samples and get the average loss\n",
    "            losses.append(running_loss / N)\n",
    "            pbar.set_description(f\"Loss {losses[-1]:.05f}\")\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f13fc67-0ee0-46bb-aae8-71e7168ca5b4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d041c6ad7fd353417b59611b02295c0",
     "grade": false,
     "grade_id": "cell-c3f1ec61ffc8ed65",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__Question 1.5__ Train the neural network. Here you simply have to run the following cell and check that the resulting plot looks similar to the one in the PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc0e90b-b420-4c7f-83d9-3d29cb830e68",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef2a52bb1730687eb2d5f7bd82fcbe87",
     "grade": false,
     "grade_id": "cell-63cbb51cf91cb030",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_and_plot_myneuralnet(n_hidden: int, epochs: int, batch_size: int, learn_rate: float, N: int):\n",
    "    \"\"\" Trains a MyNeuralNet with the specified parameters, and plots the learned function and the training curve\n",
    "    \n",
    "    Args:\n",
    "        n_hidden: number of hidden neurons of the model\n",
    "        epochs: the number of epochs, i.e., of complete passes over the data set\n",
    "        batch_size: the batch size to use in minibatch gradient descent\n",
    "        learn_rate: the learning rate to use in minibatch gradient descent\n",
    "        N: the number of data points in the training set. The training data is generated by the function get_training_data_myneuralnet.\n",
    "    \"\"\"\n",
    "    model = MyNeuralNet(n_hidden=n_hidden)\n",
    "    losses = train_myneuralnet(model, epochs=epochs, batch_size=batch_size, learn_rate=learn_rate, N=N)\n",
    "    X_train, y_train = next(get_training_data_myneuralnet(N, N))  # load the whole data set\n",
    "    X_train = X_train.flatten()\n",
    "    y_train = y_train.flatten()\n",
    "    X_plot = np.linspace(-1, 1)\n",
    "    y_plot = model.forward(X_plot.reshape(-1, 1)).flatten()\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4), tight_layout=True)\n",
    "    ax1.scatter(X_train, y_train, label='Training data')\n",
    "    ax1.plot(X_plot, y_plot, label='Learned function', color='red')\n",
    "    ax1.legend(loc='best')\n",
    "    ax1.set_title('Training outcome')\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('y')\n",
    "    ax2.semilogy(np.arange(epochs)+1, losses)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_title('Learning curve')\n",
    "    plt.show()\n",
    "\n",
    "train_and_plot_myneuralnet(n_hidden=200, epochs=1500, batch_size=4, learn_rate=0.01, N=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a0c208-a83f-4958-9bb4-4b981de3cb2f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "168f2388e960103f228ccc70f7b5a07d",
     "grade": false,
     "grade_id": "cell-0211d3dc4a00198d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Convolutions\n",
    "__Question 1.6__ Implement the function `add_padding`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc950ab-a11a-46e9-82b1-91d5fcef8fd6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b15f18da51abfda30c4a4374483e832",
     "grade": false,
     "grade_id": "cell-f2cb2f6a233807eb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def add_padding(image: np.ndarray, P: int) -> np.ndarray:\n",
    "    \"\"\" Adds padding to a batch of images.\n",
    "        \n",
    "    The padding valu should be 0. Padding images should not change the number of channels or the batch size.\n",
    "    \n",
    "    Args:\n",
    "        image: Batch of images as a numpy array of shape (batch_size, height, width, n_channels).\n",
    "        P: Number of zeros to add at all four sides of each image.\n",
    "        \n",
    "    Returns:\n",
    "        The padded image as a numpy array of shape (batch_size, height + 2P, width + 2P, n_channels).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd67c26-f53d-4d6c-b8b7-a69d9e38dd47",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8be5e04e25c0e83ee1fee0a08572896",
     "grade": false,
     "grade_id": "cell-681817e77a48cb80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the following cell to make sure your implementation outputs the correct shape, uses the correct padding value of 0, and works correctly if `P=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c95d5b-56da-4d7d-973a-bb3f3fd924ef",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "add1ada644f675cdfafed74a4711ab94",
     "grade": true,
     "grade_id": "test__padding-sanity-check",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "__batch_size = 5\n",
    "__height = 16\n",
    "__width = 26\n",
    "__n_channels = 3\n",
    "__padding = 2\n",
    "__images = np.random.randn(__batch_size, __height, __width, __n_channels)\n",
    "__padded_images = add_padding(__images, __padding)\n",
    "\n",
    "__target_shape = (__batch_size, __height + 2 * __padding, __width + 2 * __padding, __n_channels)\n",
    "assert __padded_images.shape == __target_shape, f\"For a batch of {__batch_size} images of height {__height} and width {__width} with {__n_channels} channels, the padded image batch should have shape {__target_shape}, but had shape {__padded_images.shape}\"\n",
    "\n",
    "__padded_images[:, __padding:-__padding, __padding:-__padding, :] = 0\n",
    "assert np.allclose(__padded_images, 0), \"The values added by the padding should all be 0.\"\n",
    "\n",
    "assert np.all(__images == add_padding(__images, 0)), \"If P=0, the padding function should not change the input batch, but your implementation did.\"\n",
    "\n",
    "clear_output()\n",
    "CHECKS_PASSED_MESSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b85f00-5883-4978-861e-62051690d554",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca0847c27753c21c2d72c62a448efd74",
     "grade": true,
     "grade_id": "test__padding-sanity-1",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is used for grading. Do not remove. Do not change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f86f3b6-8c91-4f4a-aba3-6c213e4fc07d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3965ea420745f10aa357eaad443d40e7",
     "grade": false,
     "grade_id": "cell-ef09cff4589a77d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__Question 1.7__ Implement the function `convolve`. We have already given you some code to start with. Particularly, `F_out` should be the number of channels your convolution outputs, `h_out` should be the height of the images your convolution outputs, and `w_out` should be the width of the images that your convolution outputs. You only have to fill in the part of the code that performs the actual convolution of the input image batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780e6b3a-212a-448b-ab11-af13069721a6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "072d9d35dd64b426607539ae1b245a37",
     "grade": false,
     "grade_id": "cell-397cd3cabc1e2e3f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def convolve(kernels: np.ndarray, images: np.ndarray, stride: int) -> np.ndarray:\n",
    "    \"\"\" Computes the convolution of a given batch of images with given kernels and a given stride.\n",
    "    \n",
    "    You should assume that the given images are already properly padded.\n",
    "    \n",
    "    Args:\n",
    "        kernels: The kernels as a numpy array of shape (K, K, F_in, F_out).\n",
    "        images: The batch matrix containing the images as a numpy array of shape (batch_size, h_in, w_in, F_in).\n",
    "        stride: The positive stride.\n",
    "    \n",
    "    Returns:\n",
    "        The convolved batch of images as a numpy array of shape (batch_size, h_out, w_out, F_out).\n",
    "    \"\"\"\n",
    "    batch_size, h_in, w_in, F_in = images.shape  # extract shape information\n",
    "    F_out = kernels.shape[3]  # number of output channels of the kernels\n",
    "    K = kernels.shape[0]  # size of the kernels\n",
    "    \n",
    "    # make sure the number of input channels matches\n",
    "    assert F_in == kernels.shape[2], f\"Size mismatch: images and kernels have different number of input filters ({F_in} != {kernels.shape[2]}).\"\n",
    "    \n",
    "    # make sure every kernel is square\n",
    "    assert kernels.shape[0] == kernels.shape[1], \"Every kernel must be a square matrix.\"\n",
    "    \n",
    "    h_out = (h_in - K) / stride + 1  # target height of the convolved output\n",
    "    w_out = (w_in - K) / stride + 1  # target width of the convolved output\n",
    "    \n",
    "    # make sure that height and width are integers (i.e., that the kernels \"fit\" the image in size)\n",
    "    assert int(h_out) == h_out and int(w_out) == w_out, \"Incompatible dimensions.\"\n",
    "    h_out = int(h_out)  # cast height from float to int\n",
    "    w_out = int(w_out)  # cast width from float to int\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddc6b7b-4c35-4fee-b446-a509a95f582f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac8a1f850ff74542648eb5bb6368d3e0",
     "grade": false,
     "grade_id": "cell-321d89b150c47563",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the following cell to make sure that your convolution produces the correct shape on a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf3940b-db21-4b5a-9d82-ad2a8906d36b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "059ef1dd87bf231baffc27983ef73dac",
     "grade": true,
     "grade_id": "cell-7767036a439ac7b8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "__kernel_size = 2\n",
    "__f_out = 4\n",
    "__stride = 2\n",
    "__h_in = 4\n",
    "__w_in = 6\n",
    "__kernels = np.linspace(0, 1, __kernel_size * __kernel_size * 3 * __f_out).reshape(__kernel_size, __kernel_size, 3, __f_out)  # 4 kernels of shape (2, 2, 3)\n",
    "__images = np.linspace(0, 10, 2 * 4 * 6 * 3).reshape(2, __h_in, __w_in, 3)  # 2 images of size 4x6 with 3 filters\n",
    "__batch_size = __images.shape[0]\n",
    "__output = convolve(__kernels, __images, __stride)\n",
    "\n",
    "__target_shape = (__batch_size, (__h_in - __kernel_size) // __stride + 1, (__w_in - __kernel_size) // __stride + 1, __f_out)\n",
    "assert __output.shape == __target_shape, f\"The output of your convolution should be of shape {__target_shape} for a batch of {__batch_size} {__images.shape[1:]} images and a stride of {__stride}, but was {__output.shape}.\"\n",
    "\n",
    "clear_output()\n",
    "CHECKS_PASSED_MESSAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6faa3f4-bccd-4f7c-811b-ef68a96a0d35",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "472b207d48e9e430eb7f86885f183196",
     "grade": false,
     "grade_id": "cell-eb056498099bad2b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__Question 1.8__ Perform sharpening, edge detection, and blurring of the given example image. Here you simply have to run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af069e0-2f0c-4ae1-a197-e15f8f9d2c94",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "934f3ff1145526d06340a6af9f9de2b9",
     "grade": false,
     "grade_id": "cell-a1dc1b45af02b38a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "EXAMPLE_KERNELS = np.dstack((\n",
    "    np.array([ [0, 0, 0], [0, 1, 0], [0, 0, 0] ]),\n",
    "    np.array([ [0, -1, 0], [-1, 5, -1], [0, -1, 0] ]),\n",
    "    np.array([ [1, 0, -1], [0, 0, 0], [-1, 0, 1] ]), \n",
    "    np.array([ [0, 1, 0], [1, -4, 1], [0, 1, 0] ]),\n",
    "    np.array([ [-1, -1, -1], [-1, 8, -1], [-1, -1, -1] ]),\n",
    "    np.array([ [1, 2, 1], [2, 4, 2], [1, 2, 1] ]) / 16\n",
    "))\n",
    "\n",
    "\n",
    "def filter_example():\n",
    "    example_img = mpimg.imread(EXAMPLE_IMAGE)\n",
    "    plt.imshow(example_img)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title('Example Image')\n",
    "    \n",
    "    # Add a batch dimension to match with our requirements\n",
    "    example_img = example_img[np.newaxis, :, :, :]\n",
    "    filtered_images = np.zeros((EXAMPLE_KERNELS.shape[2], *example_img.shape[1:]), dtype=float)\n",
    "    example_img = np.pad(example_img.copy(), [(0, 0), (1, 1), (1, 1), (0, 0)])\n",
    "    \n",
    "    for b in range(filtered_images.shape[0]):\n",
    "        inactive = np.zeros((3, 3), dtype=float)\n",
    "        active = EXAMPLE_KERNELS[:, :, b]\n",
    "        red = np.dstack((active, inactive, inactive))\n",
    "        green = np.dstack((inactive, active, inactive))\n",
    "        blue = np.dstack((inactive, inactive, active))\n",
    "        total = np.stack((red, green, blue), axis=3)\n",
    "        filtered_images[b, :, :, :] = convolve(total, example_img, 1)[0, :, :, :]\n",
    "    # The convolution operation puts some values outside of the range [0, 1], so we clip them\n",
    "    filtered_images = np.clip(filtered_images, 0, 1)\n",
    "    # You may need to re-order this list to have the correct titles\n",
    "    names = ['Identity', 'Sharpening', 'Edge detection 1', 'Edge detection 2', 'Edge detection 3', 'Gaussian blur 3x3']\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(11,7), constrained_layout=True)\n",
    "    # plt.subplots_adjust(wspace=0.1, hspace=0.01)\n",
    "\n",
    "    for b in range(filtered_images.shape[0]):\n",
    "        fil = filtered_images[b, :, :, :]\n",
    "        i = b // 3\n",
    "        j = b % 3\n",
    "        axs[i, j].imshow(fil)\n",
    "        axs[i, j].set_title(names[b])\n",
    "        axs[i, j].set_xticks([])\n",
    "        axs[i, j].set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "filter_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f7174f-c777-4c19-b5d5-b0bf0bc72d87",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2fff032a500417d193c0e6374422592",
     "grade": true,
     "grade_id": "test__convolution",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is used for grading. Do not remove. Do not change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91c5ccd-a3e8-4c1a-a996-1816e95dbdbb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d441628840981ac0bc59d051aa86d094",
     "grade": false,
     "grade_id": "cell-3ce607a7b0c05772",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Convolutions in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8af47b-92c2-4263-899b-9a4b124f554b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77892f88984223bc6b6309c2ce2e8d05",
     "grade": false,
     "grade_id": "cell-e23851908178d33f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch import Tensor\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189fcc00-f3b6-40f6-8ef9-43aa0c68014d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1efec95259427aeb180a503413240859",
     "grade": false,
     "grade_id": "cell-6c97e662219a0bfb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the following cell to load the data from the `DATA` directory. Here you don't have to implement anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc159276-f7b0-43f0-87b4-32e8e6c0eb1b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "641853982b0a5f76aa215694911ba432",
     "grade": false,
     "grade_id": "cell-0f09aecc17a8ea26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "transformations = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_valid_ds = ImageFolder(\n",
    "    root=str(DATA/\"train\"),\n",
    "    transform=transformations\n",
    ")\n",
    "\n",
    "train_valid_size = len(train_valid_ds)\n",
    "train_size = int(0.7 * train_valid_size)\n",
    "valid_size = train_valid_size - train_size\n",
    "\n",
    "train_ds, valid_ds = random_split(train_valid_ds, [train_size, valid_size])\n",
    "\n",
    "test_ds = ImageFolder(\n",
    "    root=str(DATA/\"test\"),\n",
    "    transform=transformations\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c92d6b6-02b4-49b4-90cb-eaa468d08a94",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "42dd8ba82e36780e1415728d7920ae47",
     "grade": false,
     "grade_id": "cell-ccd0e6ee3bd43dcf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__Question 2.1__ Implement the `SimpLeNet` Neural Network as stated in the assignment PDF. In the `__init__` method, you should initialise all the `torch` modules that you need for the model. The `forward` method should perform a forward pass through the complete model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb24723-e33b-4a5d-af69-6d44dc584830",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "091230ea4f810aabfa02eee0c9e09d62",
     "grade": false,
     "grade_id": "cell-f80079da20e6b925",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, ReLU, Sigmoid\n",
    "\n",
    "\n",
    "class SimpLeNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\" Initialized the neural network.\n",
    "        \n",
    "        Here, you define all the necessary layers that are subsequently used in the forward pass.\n",
    "        Hint: Take a look at the imports above.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv = ...\n",
    "        self.pool = ...\n",
    "        self.flatten = ...\n",
    "        self.ff1 = ...\n",
    "        self.relu = ...\n",
    "        self.ff2 = ...\n",
    "        self.sigmoid = ...\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\" Performs a forward pass through the entire network.\n",
    "        \n",
    "        Args:\n",
    "            x: Input batch matrix as a pytorch tensor of shape (batch_size, 224, 224, 3).\n",
    "            \n",
    "        Returns:\n",
    "            The output as a pytorch tensor of shape (batch_size, 1).\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5ef5d3-9784-41f5-b1d7-693e4ec54ad9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c19e5dadd7f7c53162dfe3058c3933f6",
     "grade": false,
     "grade_id": "cell-f8f064c98f90ff9b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the following cell to make sure a forward pass through your model produces the correct output shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c9a8c5-08a7-4879-ab4b-1d9bff301079",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df5b7da9f9a225db0aa39ebc18baf631",
     "grade": true,
     "grade_id": "test__simple-net-sanity-check",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "__sample, _ = train_ds[0]\n",
    "__my_neural_network = SimpLeNet()\n",
    "__sample_batch = __sample.unsqueeze(0)\n",
    "\n",
    "__output =__my_neural_network(__sample_batch)\n",
    "__target_output_shape = (1, 1)\n",
    "assert __output.shape == __target_output_shape, f\"Your neural network receives an input of shape {tuple(__sample_batch.shape)} and should return an output of shape {__target_output_shape}, but output was of shape {tuple(__output.shape)}.\"\n",
    "\n",
    "clear_output()\n",
    "CHECKS_PASSED_MESSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f920efb2-19b4-410e-9d05-be597f405db3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c8a0c553d79f9ea752c87a157180e1c",
     "grade": true,
     "grade_id": "test__simple-net",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is used for grading. Do not remove. Do not change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2978bf80-f2a1-47b4-9cb5-b2c7068d1b61",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "59496b6a19ccb25570d3112f08a488fd",
     "grade": false,
     "grade_id": "cell-b41cc71847b1521e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__Question 2.2__ Implement the function `train` that trains a given `model` for a given number of `epochs` using a given `batch_size` and `learning_rate`. We already implemented part of the code for you. You should use the `criterion` to compute the loss of a batch of predictions and targets. You should use the `optimizer` to perform the actual gradient descent. The `train_loader` already holds all input batches. The missing part that you have to implement is to make predictions for the `inputs`, calculate the loss given these predictions and the `labels`, backpropagate the loss, and perform an optimization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b01906-132b-4fbe-9d2e-f8ce20c5adf0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5fec140025017e97184877f6ecc816a2",
     "grade": false,
     "grade_id": "cell-6a09eaff5045ceea",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def train(model, batch_size, epochs, learning_rate):\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    with tqdm(range(epochs)) as pbar:\n",
    "        for epoch in pbar:  # loop over the dataset multiple times\n",
    "            running_loss = 0.0\n",
    "            samples_in_epoch = 0\n",
    "            \n",
    "            with tqdm(train_loader) as ebar:\n",
    "                for inputs, labels in ebar:\n",
    "                    optimizer.zero_grad()  # reset the parameter gradients to 0\n",
    "                    labels = labels.float()  # cast label type to float\n",
    "                    # forward + backward + optimize\n",
    "                    # YOUR CODE HERE\n",
    "                    raise NotImplementedError()\n",
    "                    running_loss += loss.item() * inputs.shape[0]  # keep track of current loss\n",
    "                    samples_in_epoch += inputs.shape[0]\n",
    "                    ebar.set_description(f\"Epoch {epoch+1} | Loss {running_loss/samples_in_epoch:0.04f}\")\n",
    "                losses.append(running_loss / len(train_ds))  # compute and store average loss during the epoch\n",
    "                \n",
    "            pbar.set_description(f\"Total Training | Loss {losses[-1]:.04f}\")  # show loss during the last epoch\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3219395-e26b-414c-a33c-869d3f545fa4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e65f045d9e56019feb125044c80551eb",
     "grade": false,
     "grade_id": "cell-80059e31687c1211",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__Question 2.3__ Run the following cell to train your model. Note that this might take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb770a95-57d6-418c-b971-3bf18ce7f0c9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bf8ac3fb3e33d07f4a3025be2703698",
     "grade": false,
     "grade_id": "cell-ff2413c9bda6e115",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "__model = SimpLeNet()\n",
    "__epochs = 5\n",
    "__learning_rate = 0.01\n",
    "__batch_size = 128\n",
    "\n",
    "losses = train(__model, __batch_size, __epochs, __learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d25188-b0a9-4593-be33-13d34208cc38",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "219b54715cec97bcb7f4ea12b0731630",
     "grade": false,
     "grade_id": "cell-490e857e4f772eb8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the following cell to evaluate the accuracy of the model on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0f1887-3dc6-4c28-9b39-c149475ec498",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "37514c41d7ce9c8d3333e2d1b2a4f599",
     "grade": false,
     "grade_id": "cell-7add5ec1286a1aef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model)-> float:\n",
    "    validation_loader = DataLoader(valid_ds)\n",
    "    correct_classifications = 0\n",
    "    \n",
    "    for inputs, labels in validation_loader:\n",
    "        labels = labels.float()  # cast label type to float\n",
    "        predictions = model(inputs).squeeze(-1) >= 0.5  # map probabilities to binary classifications\n",
    "        correct_classifications += torch.sum(predictions.int() == labels)  # count number of correct classifications\n",
    "\n",
    "    return correct_classifications / len(valid_ds)\n",
    "        \n",
    "accuracy = evaluate(__model)\n",
    "print(f\"The model achieved an accuracy of {100 * accuracy:.2f}% on the validation dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aa6785-eb4c-481a-8e96-55555819d7fe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02cab0e79ca4a94c9fa4fc9c4c98ec36",
     "grade": false,
     "grade_id": "cell-6e8860a6971fb7bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Extending Pretrained Models\n",
    "__Question 3.1__ Implement the `AdaptedResNet` Neural Network. In the constructor (`__init__`), make sure that only gradients of the `classifier` are tracked by PyTorch and that gradients of the ResNet module are not being tracked. Additionally, implement the `forward` function of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458086b3-7190-4e27-91c5-2f3902cd67bf",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a55801b4354de107c77d1af63342ab0",
     "grade": false,
     "grade_id": "cell-6ac7d1ebc497a190",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "class AdaptedResNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\" Initializes the module.\n",
    "        \n",
    "        We load the ResNet module, select the layers that we are interested in and set ResNet to evaluation mode as we \n",
    "        don't plan on training the ResNet part of the model.\n",
    "        Additionally, we define a custom classifier that works with the representations obtained from the ResNet model.\n",
    "        \n",
    "        Here, your task is to make sure that PyTorch doesn't track the gradients of the ResNet model which would add\n",
    "        a lot of computational overhead which is not necessary as we don't want to train the ResNet model anyway. For this,\n",
    "        each PyTorch module already implements the function requires_grad_(...) which you can use\n",
    "        to prevent PyTorch from tracking gradients for specific modules.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # load pre-trained ResNet model from checkpoint\n",
    "        # normally, you would need to specify arguments in models.resnet18 to specify which weights you want to load\n",
    "        # here, we have already downloaded the weights for you\n",
    "        resnet = models.resnet18()\n",
    "        weights = torch.load(DATA / \"resnet18_weights.pth\", weights_only=True)\n",
    "        resnet.load_state_dict(weights)\n",
    "        \n",
    "        # use ResNet without the last feed-forward layer as backbone model\n",
    "        self.backbone = torch.nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.backbone.eval()  # deactivate the dropout layers of ResNet\n",
    "\n",
    "        # add a custom classification step\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(512, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Do not change what precedes\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\" Performs a forward pass through the neural network.\n",
    "        \n",
    "        First, use the ResNet network to obtain an expressive latent representation of the image.\n",
    "        Then, use the custom classifier to make an actual prediction about the input.\n",
    "        \n",
    "        Args:\n",
    "            x: Batch of input images as a pytorch tensor of shape (batch_size, 3, 224, 224).\n",
    "            \n",
    "        Returns:\n",
    "            A batch of predictions as a pytorch tensor of shape (batch_size, 1).\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def train(self, mode=True):\n",
    "        \"\"\" Sets the module in training mode and ensures that ResNet remains in eval mode.\n",
    "        \"\"\"\n",
    "        super().train(mode)\n",
    "        self.backbone.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05a1fb4-d90e-4ba6-a571-4873d9dd1ac4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7e474bf4a8bda630c961a2f53333ec3",
     "grade": false,
     "grade_id": "cell-e0a1ec811c12e0b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the following cell to make sure you output the right parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e01d6f-4fcd-4e7b-861f-7d43a79cf101",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1a8b4bc85303941a475501c6852d827",
     "grade": true,
     "grade_id": "test__vgg-sanity-check-1",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "__model = AdaptedResNet()\n",
    "__parameters = __model.parameters()\n",
    "__n_parameters = sum(parameter.numel() for parameter in __parameters if parameter.requires_grad)\n",
    "__target_n_parameters = 8225\n",
    "\n",
    "assert __n_parameters == __target_n_parameters, f\"The classifier has {__target_n_parameters} parameters, but your model has {__n_parameters} trainable parameters. Hint: Use the .requires_grad_(False) method of the ResNet module to stop tracking gradients of the ResNet module.\"\n",
    "\n",
    "clear_output()\n",
    "CHECKS_PASSED_MESSAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f074cc-9c83-41bd-aae0-780e007f90ef",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "18c0549c161e5ffe822f4d66cba2d767",
     "grade": false,
     "grade_id": "cell-6eb7dea9899cd4e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the following cell to make sure the output of the network has the expected properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daacc42a-d341-4ba4-ac60-1ede80f56d6d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c5b8af06368502e23db1ee04016aaff",
     "grade": true,
     "grade_id": "test__vgg-sanity-check-2",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "__model = AdaptedResNet()\n",
    "__batch_size = 16\n",
    "__random_batch = torch.rand(__batch_size, 3, IMG_SIZE, IMG_SIZE)\n",
    "__predictions = __model(__random_batch)\n",
    "\n",
    "__target_shape = (__batch_size, 1)\n",
    "assert __predictions.shape == __target_shape, f\"The output of your model should have shape {__target_shape}, but your returned a tensor of shape {tuple(__predictions.shape)}.\"\n",
    "assert torch.all(__predictions >= 0), \"The output of your model should be probabilities, but you returned values smaller than 0.\"\n",
    "assert torch.all(__predictions <= 1), \"The output of your model should be probabilities, but you returned values bigger than 1.\"\n",
    "\n",
    "clear_output()\n",
    "CHECKS_PASSED_MESSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd6d0a7-d31f-4074-ba6d-0922dd1e1135",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e4ffcd04e863af3a2c851adf287491c6",
     "grade": true,
     "grade_id": "test__vgg",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is used for grading. Do not remove. Do not change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66ca3ce-814c-4fc3-bd13-3bc5354eba9e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c8a6f3c48025482c2cc6458b97e4d78c",
     "grade": false,
     "grade_id": "cell-cb20dfcbea8b6c0d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__Question 3.2__ Implement the function `early_stopping_check` that decided whether to stop the training based on the loss history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0bb6a3-ccaa-44ed-a941-48b5c4e2bfce",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d0d10813cd66ca0600d36a8664e6e0f",
     "grade": false,
     "grade_id": "cell-6bcf54c6ca7c18a0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def early_stopping_check(losses: list[float], threshold: int) -> bool:\n",
    "    \"\"\" Checks whether to stop early during training.\n",
    "    The check should decide to stop early if and only if a certain theshold of losses have been monotonoically increasing.\n",
    "    \n",
    "    Args:\n",
    "        losses: List of scalar losses for each epoch. For each epoch there is exactly one loss. losses[0] corresponds to the first epoch. losses[-1] corresponds to the last epoch.\n",
    "        threshold: Number of latest losses to be monotonically increasing for the training to stop early.\n",
    "        \n",
    "    Returns:\n",
    "        True if the training should be stopped and otherwise False.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16d7dc9-d576-4ead-97ff-06a6cd699bf9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34f8649e7e891351ca3da2423407621e",
     "grade": true,
     "grade_id": "test__early-stopping",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is used for grading. Do not remove. Do not change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0050d79f-bb60-48e8-b3e1-67a5fb8efdfc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b52a91d1b8e32b50079b157e14253677",
     "grade": false,
     "grade_id": "cell-01ac89e9af1c58cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__Question 3.3__ Implement the `forward` pass of the `DropoutAdaptedResNet` Neural Network. The model should behave just like the `AdaptedResNet`, but should randomly set $20\\%$ of the representation between the ResNet output and the custom classifier to $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53c63c5-9fac-4a8c-a8a3-b264e1bd84cd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ceed62f25f36e0f2cc263a8f6d29a242",
     "grade": false,
     "grade_id": "cell-1ff108b81d1c48f6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn.functional import dropout\n",
    "\n",
    "\n",
    "class DropoutAdaptedResNet(AdaptedResNet):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53801c3-2812-4885-ac14-542b3468867e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6471c9aa64b676097960543c572bb87",
     "grade": true,
     "grade_id": "test__dropout-vgg-sanity-check",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "__model = DropoutAdaptedResNet()\n",
    "assert isinstance(__model, AdaptedResNet), \"Your model should extend the `AdaptedResNet` model. You are not allowed to change the class signature.\"\n",
    "assert hasattr(__model, \"backbone\"), \"Your model should contain a module called `bachbone`. You are not allowed to change attribute names.\"\n",
    "assert hasattr(__model, \"classifier\"), \"Your model should contain a module called `classifier`. You are not allowed to change attribute names.\"\n",
    "\n",
    "clear_output()\n",
    "CHECKS_PASSED_MESSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667d50b5-2753-4700-934e-4c6a65fa0d4c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3de406b2376e7bd0bf5733dc29f01177",
     "grade": true,
     "grade_id": "test__dropout-vgg",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is used for grading. Do not remove. Do not change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248f8102-9959-4c21-8c22-870dc08ef9ac",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a09eb4fa1815f207f879e9b835c8133b",
     "grade": false,
     "grade_id": "cell-e46561bb57a9bd50",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__Question 3.4__ Implement the function `store_checkpoint`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e817d02-5731-4361-add2-0c4e5637f690",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9376040ef1934a1d44491dd069165e33",
     "grade": false,
     "grade_id": "cell-95310e4c93b12fb0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = ROOT / \"checkpoints\"\n",
    "CHECKPOINT_DIR.mkdir(exist_ok=True, parents=False)\n",
    "\n",
    "def store_checkpoint(model: torch.nn.Module, epoch: int) -> None:\n",
    "    \"\"\" Saves the state of a model to disk.\n",
    "    \n",
    "    Specifically, the model should be saved in a .pt file in the CHECKPOINT_DIR folder.\n",
    "    The file name of the model should be `model-{epoch}`.\n",
    "    \n",
    "    Args:\n",
    "        model: Module to be saved to disk.\n",
    "        epoch: Epoch at which the model was saved.\n",
    "        \n",
    "    Returns:\n",
    "        Nothing.\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db4e560-3858-41dd-b5f3-4484cf4e74ef",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b17bd763a37a3d00aac3e4eb63f4a508",
     "grade": true,
     "grade_id": "test__store-checkpoint-sanity-check",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "__model = DropoutAdaptedResNet()\n",
    "__checkpoint_path = CHECKPOINT_DIR / \"model-0.pt\"\n",
    "store_checkpoint(__model, 0)\n",
    "__loaded_model = torch.load(__checkpoint_path)\n",
    "assert hasattr(__loaded_model, \"parameters\"), \"Make sure the checkpoint exposes the parameters of the model directly. Do not use the state dict.\"\n",
    "\n",
    "clear_output()\n",
    "CHECKS_PASSED_MESSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4333156f-7aca-4077-aa03-488439a60a83",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eaa01852924c4b96c3a430d1d2c8492e",
     "grade": true,
     "grade_id": "test__store-checkpoint",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is used for grading. Do not remove. Do not change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cadd8f-5b48-48b7-9c6b-a909633c9ce5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "380b9f69353db6eb36782332941e798a",
     "grade": false,
     "grade_id": "cell-94960a6a55746a81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__Question 3.5__ Implement the remaining part of the training loop just as you did in Question 2.2. Here you just have to fill in the missing part in the inner `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0dfc5d-ee9c-4dfa-b49c-7f6622bccb98",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d64f954e99b5a7c8bcaab7d3fec5fd38",
     "grade": false,
     "grade_id": "cell-8ba6ab64f611aff0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def transfer_train(model: torch.nn.Module, batch_size: int, epochs: int, learning_rate: float) -> list[float]:\n",
    "    assert \"store_checkpoint\" in globals(), \"The store_checkpoint function is not defined.\"\n",
    "    assert \"early_stopping_check\" in globals(), \"The early_stopping_check function is not defined.\"\n",
    "    \n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.classifier.parameters(), lr=learning_rate)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_ds, batch_size=batch_size)\n",
    "    \n",
    "    losses = []\n",
    "    valid_losses = []\n",
    "    \n",
    "    CHECKPOINT_DIR.mkdir(exist_ok=True, parents=False)\n",
    "    store_checkpoint(model, 0)\n",
    "    \n",
    "    with tqdm(range(1, epochs + 1)) as pbar:\n",
    "        for epoch in pbar:  # loop over the dataset multiple times\n",
    "            running_loss = 0.0\n",
    "            samples_in_epoch = 0\n",
    "            with tqdm(train_loader) as ebar:\n",
    "                for i, (inputs, labels) in enumerate(ebar):\n",
    "                    optimizer.zero_grad()  # reset the parameter gradients to 0\n",
    "                    labels = labels.float()  # cast label type to float\n",
    "                    # forward + backward + optimize\n",
    "                    # YOUR CODE HERE\n",
    "                    raise NotImplementedError()\n",
    "\n",
    "                    running_loss += loss.item() * inputs.shape[0]  # keep track of current loss\n",
    "                    samples_in_epoch += inputs.shape[0]\n",
    "                    ebar.set_description(f\"Epoch {epoch} | Loss {running_loss/samples_in_epoch:0.04f}\")\n",
    "                \n",
    "            losses.append(running_loss / len(train_ds))\n",
    "            pbar.set_description(f\"Total training | Loss {losses[-1]:.02f}\")\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            samples_in_epoch = 0\n",
    "                \n",
    "            with tqdm(valid_loader) as ebar:\n",
    "                for inputs, labels in ebar:\n",
    "                    labels = labels.float()  # cast label type to float\n",
    "                    predictions = model(inputs).squeeze(-1)\n",
    "                    loss = criterion(predictions, labels)\n",
    "                    \n",
    "                    running_loss += loss.item() * inputs.shape[0]  # keep track of current loss\n",
    "                    samples_in_epoch += inputs.shape[0]\n",
    "                    ebar.set_description(f\"Epoch {epoch} | Validation Loss {running_loss/samples_in_epoch:0.04f}\")\n",
    "            \n",
    "            valid_losses.append(running_loss / len(valid_ds))\n",
    "            \n",
    "            store_checkpoint(model, epoch)\n",
    "            \n",
    "            if early_stopping_check(valid_losses, 3):\n",
    "                break\n",
    "    return losses, valid_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0b93f6-1992-4ec1-9d79-322240dacff2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3707d0540f759242098be98987908fa4",
     "grade": false,
     "grade_id": "cell-68858290de5f80a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the following cell to fine-tune your model. Note that this might take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493336a7-915f-4728-80a4-67707f127795",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5ef1cd7ca648533f8bb7db7ef2500c5",
     "grade": false,
     "grade_id": "cell-226ecc254a53672f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "np.random.seed(1)\n",
    "random.seed(2)\n",
    "torch.manual_seed(3)\n",
    "\n",
    "\n",
    "__model = DropoutAdaptedResNet()\n",
    "__batch_size = 32\n",
    "__epochs = 3\n",
    "__learning_rate = 0.001\n",
    "\n",
    "__model.train()  # set model in training mode\n",
    "losses, valid_losses = transfer_train(__model, __batch_size, __epochs, __learning_rate)  # train the model and store loss history\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0669561b-a5da-4fd9-b353-e0952a062259",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "accba0a01e55562c2b4a2ed83d49d6ec",
     "grade": false,
     "grade_id": "cell-cbb34ec68b57d420",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# plot loss history\n",
    "def plot_history():\n",
    "    epochs_axis = range(1, len(losses) + 1)\n",
    "    plt.plot(epochs_axis, losses, \"b\", label=\"Training loss\")\n",
    "    plt.plot(epochs_axis, valid_losses, \"r\", label=\"Validation loss\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title(\"Loss throughout training\")\n",
    "    \n",
    "plot_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f96e8d-6ea7-4873-8555-8ef745d2e70c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "71ff72cbd6a238d5252d6d59468439ff",
     "grade": false,
     "grade_id": "cell-dc087ff091809b46",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__Optional Question 3.6__ Implement the function `evaluate_accuracy` that computes the proportion of correctly classified data points in the test data set. The `test_loader` already hold the test data to be iterated over. You only have to implement the remaining part of the code that makes a prediction for each `input` and updates the number of correctly classified inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67810ff-f0a3-4db6-82a9-a62bfabd3e3b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "046767524b3b3ce76fc2378dfdc09f13",
     "grade": false,
     "grade_id": "cell-93d4f1eb09d21684",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(model: torch.nn.Module) -> float:\n",
    "    test_loader = DataLoader(test_ds)\n",
    "    n_correct = 0\n",
    "    \n",
    "    # count the number of correct classifications\n",
    "    for inputs, labels in tqdm(test_loader):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    return n_correct / len(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a2ab1-2ed6-434d-8053-f50f97bef74c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b93d4b19c33853a2acd7be67f317c5fd",
     "grade": false,
     "grade_id": "cell-44f5ed7ab33bb3c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the following cell to compute the accuracy of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4b42cf-41a5-4ff1-92f7-6064cc53b9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate_accuracy(__model)\n",
    "print(f\"Your model achieves an accuracy of {100 * accuracy:.2f}% on the test dataset.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "panel-cell-order": [
   "9e588f37-9ddb-4453-9112-4c15fd236c10",
   "6bfd3355-98d2-4bf6-bf60-a296b3df3d4a",
   "f4c7b2c0-e311-4cf1-9fea-a88399d604a4",
   "b52eb95c-3491-4399-a789-f6d26f02eff4",
   "b9252dde-ef04-4558-b362-6a757bd7cc8b",
   "8a297501-90be-40af-a160-d8dd3c2cd080",
   "adf0c10c-7039-41b9-9ace-23d4b05368d5",
   "a4e5f72f-420e-4136-a95e-2f7ae32fa1d8",
   "4a3ac720-da5f-4a90-badf-b27734b6ad86",
   "d4b2ba7c-07e1-4b31-860c-423d7425bba2"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
